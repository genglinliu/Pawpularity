{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af8fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages and utils\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import PIL.Image as Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from models.vgg16 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config   \n",
    "num_epochs = 1\n",
    "num_classes = 2\n",
    "batch_size = 16\n",
    "learning_rate = 1e-5\n",
    "# model_name = vgg16_bn(pretrained=True) # baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cvs data\n",
    "\n",
    "data_dir = \"../data/petfinder-pawpularity-score/\"\n",
    "\n",
    "img_train_dir = os.path.join(data_dir, 'train')\n",
    "\n",
    "def return_imgfilepath(name, folder=img_train_dir):\n",
    "    path = os.path.join(folder, f'{name}.jpg')\n",
    "    return path\n",
    "\n",
    "train_file_path = os.path.join(data_dir, 'train.csv')\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "\n",
    "# set image filepath\n",
    "train_df['file_path'] = train_df['Id'].apply(lambda x: return_imgfilepath(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd90b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(train_df['file_path'][0])\n",
    "# im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c079a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self, image_filepaths, targets, transform=None):\n",
    "        self.image_filepaths = image_filepaths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_filepaths[idx]\n",
    "        with open(image_filepath, 'rb') as f:\n",
    "            image = Image.open(f)\n",
    "            image_rgb = image.convert('RGB')\n",
    "        # image = np.array(image_rgb) / 255 # convert to 0-1\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "#         image = torch.transpose(image, (2, 0, 1))\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        image = torch.tensor(image)\n",
    "        target = torch.tensor(target)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(train_df['file_path'])\n",
    "targets = np.array(train_df['Pawpularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af76cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0814b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "# train_loader, val_loader, test_loader = load_data(batch_size, use_subset=True)\n",
    "\n",
    "def load_data(batch_size, use_subset=True):\n",
    "    \"\"\"\n",
    "    return the train/val/test dataloader\n",
    "    \"\"\"\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)\n",
    "    ])\n",
    "    \n",
    "    train_dataset = PetDataset(image_filepaths=images, targets=targets, transform=transform)\n",
    "#     val_dataset = PetDataset(image_filepaths=images, targets=targets, transform=transform)\n",
    "#     test_dataset = PetDataset(image_filepaths=images, targets=targets, transform=transform)\n",
    "    \n",
    "    indices_train = list(range(700))\n",
    "#     indices_val = list(range(150))    \n",
    "#     indices_test = list(range(150))\n",
    "    \n",
    "    train_subset = Subset(train_dataset, indices_train)\n",
    "#     val_subset = Subset(train_dataset, indices_val)\n",
    "#     test_subset = Subset(test_dataset, indices_test)\n",
    "\n",
    "    # data loader\n",
    "    train_loader = DataLoader(dataset=train_subset if use_subset else train_dataset, \n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "#     val_loader = DataLoader(dataset=val_subset if use_subset else val_dataset,\n",
    "#                                 batch_size=batch_size,\n",
    "#                                 shuffle=False)\n",
    "#     test_loader = DataLoader(dataset=test_subset if use_subset else test_dataset,\n",
    "#                                 batch_size=batch_size,\n",
    "#                                 shuffle=False)\n",
    "    \n",
    "#     return train_loader, val_loader, test_loader\n",
    "    return train_loader\n",
    "\n",
    "train_loader = load_data(batch_size, use_subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e10886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "\n",
    "class ConvNet_v1(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple two-layer CNN with sequential container\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ConvNet_v1, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(387200, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out).squeeze()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "\n",
    "def initialize_model(model, learning_rate, num_classes):\n",
    "    \"\"\"\n",
    "    initialize the model (pretrained vgg16_bn)\n",
    "    define loss function and optimizer and move data to gpu if available\n",
    "    \n",
    "    return:\n",
    "        model, loss function(criterion), optimizer\n",
    "    \"\"\"\n",
    "    \n",
    "#     num_ftrs = model.classifier[6].in_features\n",
    "#     model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()   # potential alternative: nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return model, criterion, optimizer\n",
    "\n",
    "model_name = ConvNet_v1()\n",
    "\n",
    "model, criterion, optimizer = initialize_model(model_name, learning_rate, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"simple_run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "def calc_rmse(y_pred, y_true):\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, num_epochs):\n",
    "    \"\"\"\n",
    "    Move data to GPU memory and train for specified number of epochs\n",
    "    Also plot the loss function and save it in `Figures/`\n",
    "    Trained model is saved as `cnn.ckpt`\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs): # repeat the entire training `num_epochs` times\n",
    "        # for each training sample\n",
    "        loss_hist = []\n",
    "        step_hist = []\n",
    "        for i, (images, label) in (enumerate(train_loader)):\n",
    "            \n",
    "            model.train()\n",
    "            train_pred = list()\n",
    "            train_true = list()\n",
    "            \n",
    "            # move to gpu if available\n",
    "            images = images.to(device).float()\n",
    "            label = label.to(device).float()\n",
    "                \n",
    "            # forward pass\n",
    "            out = model(images)\n",
    "            loss_func = nn.MSELoss()\n",
    "            loss = torch.sqrt(loss_func(out, label))\n",
    "            \n",
    "            print(type(loss))\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_true += label.cpu().detach().numpy().tolist()\n",
    "            train_pred += out.cpu().detach().numpy().tolist()\n",
    "\n",
    "            train_rmse = calc_rmse(np.array(train_pred), np.array(train_true))\n",
    "        \n",
    "            print('Train rmse: {}'.format(train_rmse))\n",
    "        \n",
    "    torch.save(model.state_dict(), experiment_name+'.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_loader, model, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b814a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
