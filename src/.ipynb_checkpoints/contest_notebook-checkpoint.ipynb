{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af8fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages and utils\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import PIL.Image as Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from models.vgg16 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c352e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config   \n",
    "\n",
    "data_dir = \"../data/petfinder-pawpularity-score/\"\n",
    "\n",
    "num_epochs = 1\n",
    "num_classes = 2\n",
    "batch_size = 16\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# model_name = vgg16_bn(pretrained=True) # baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0332ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "display(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b91936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Dataset - might need modification later for covariates idk yet\n",
    "\n",
    "class PetDataset(Dataset):\n",
    "    def __init__(self, image_filepaths, targets, transform=None):\n",
    "        self.image_filepaths = image_filepaths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_filepaths[idx]\n",
    "        \n",
    "        with open(image_filepath, 'rb') as f:\n",
    "            image = Image.open(f)\n",
    "            image_rgb = image.convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        image = torch.tensor(image)\n",
    "        target = torch.tensor(self.targets[idx])\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d7712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cvs data into dataframes\n",
    "\n",
    "def get_dataframe(data_dir, is_train=True):\n",
    "    \n",
    "    if is_train:\n",
    "        image_dir = os.path.join(data_dir, 'train')\n",
    "        file_path = os.path.join(data_dir, 'train.csv')\n",
    "    else:\n",
    "        image_dir = os.path.join(data_dir, 'test')\n",
    "        file_path = os.path.join(data_dir, 'test.csv')\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # set image filepath\n",
    "    df['img_file_path'] = df['Id'].apply(lambda x: os.path.join(image_dir, f'{x}.jpg'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = get_dataframe(data_dir, is_train=True)\n",
    "test_df = get_dataframe(data_dir, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0814b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get DataLoader\n",
    "\n",
    "def load_data(batch_size, is_train=True, use_subset=False):\n",
    "    \"\"\"\n",
    "    return the train dataloader\n",
    "    \"\"\"\n",
    "    \n",
    "    if is_train:\n",
    "        df = get_dataframe(data_dir, is_train=True)\n",
    "        images = np.array(df['file_path'])\n",
    "        targets = np.array(df['Pawpularity'])\n",
    "    else:\n",
    "        df = get_dataframe(data_dir, is_train=False)\n",
    "        images = np.array(df['file_path'])\n",
    "        targets = np.zeros_like(images)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)\n",
    "    ])\n",
    "    \n",
    "    dataset = PetDataset(image_filepaths=images, targets=targets, transform=transform)\n",
    "    \n",
    "    subse_ind = list(range(500))\n",
    "    \n",
    "    data_subset = Subset(dataset, subse_ind)\n",
    "\n",
    "    # data loader\n",
    "    data_loader = DataLoader(dataset=data_subset if use_subset else dataset, \n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "    \n",
    "    return data_loader\n",
    "\n",
    "train_loader = load_data(batch_size, is_train=True)\n",
    "test_loader = load_data(batch_size, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e10886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "\n",
    "class ConvNet_v1(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple two-layer CNN with sequential container\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ConvNet_v1, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(387200, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out).squeeze()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "\n",
    "def initialize_model(model, learning_rate, num_classes):\n",
    "    \"\"\"\n",
    "    initialize the model\n",
    "    define loss function and optimizer and move data to gpu if available\n",
    "    \n",
    "    return:\n",
    "        model, loss function(criterion), optimizer\n",
    "    \"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return model, criterion, optimizer\n",
    "\n",
    "model_name = ConvNet_v1()\n",
    "\n",
    "model, criterion, optimizer = initialize_model(model_name, learning_rate, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting loss curve\n",
    "\n",
    "def make_plots(step_hist, loss_hist):\n",
    "    plt.plot(step_hist, loss_hist)\n",
    "    plt.xlabel('train_iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    # plt.title('epoch'+str(epoch+1))\n",
    "    plt.title(experiment_name)\n",
    "    plt.savefig(experiment_name)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "experiment_name = \"simple_run\"\n",
    "\n",
    "def calc_rmse(y_pred, y_true):\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, num_epochs):\n",
    "    \"\"\"\n",
    "    Move data to GPU memory and train for specified number of epochs\n",
    "    Also plot the loss function and save it in `Figures/`\n",
    "    Trained model is saved as `cnn.ckpt`\n",
    "    \"\"\"\n",
    "    # for each training sample\n",
    "    loss_hist = []\n",
    "    step_hist = []\n",
    "    for i, (images, label) in (enumerate(train_loader)):\n",
    "\n",
    "        model.train()\n",
    "        train_pred = list()\n",
    "        train_true = list()\n",
    "\n",
    "        # move to gpu if available\n",
    "        images = images.to(device).float()\n",
    "        label = label.to(device).float()\n",
    "\n",
    "        # forward pass\n",
    "        out = model(images)\n",
    "        loss = torch.sqrt(criterion(out, label))\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i // 5000 == 0:\n",
    "            train_true += label.cpu().detach().numpy().tolist()\n",
    "            train_pred += out.cpu().detach().numpy().tolist()\n",
    "\n",
    "            train_rmse = calc_rmse(np.array(train_pred), np.array(train_true))\n",
    "            \n",
    "            step_hist.append(i)\n",
    "            loss_hist.append(train_rmse)\n",
    "            print('Train rmse: {}'.format(train_rmse))\n",
    "            \n",
    "    \n",
    "        # plot\n",
    "        make_plots(step_hist, loss_hist)\n",
    "\n",
    "torch.save(model.state_dict(), experiment_name+'.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_loader, model, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060747c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "\n",
    "# iterate over test data\n",
    "print('Making predictions...')\n",
    "test_pred = []\n",
    "\n",
    "for test_images, test_labels in test_loader:\n",
    "    test_images = test_images.to(device).float()\n",
    "    \n",
    "    # forward\n",
    "    out = model(test_images)\n",
    "    test_pred += out.cpu().detach().numpy().tolist()\n",
    "\n",
    "# write to file\n",
    "output = pd.DataFrame({\"Id\": test_df['Id'], \"Pawpularity\": test_pred})\n",
    "output.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output\n",
    "\n",
    "output_df = pd.read_csv('submission.csv')\n",
    "output_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
