{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10370e16",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-21T17:46:52.957083Z",
     "iopub.status.busy": "2021-12-21T17:46:52.956155Z",
     "iopub.status.idle": "2021-12-21T17:46:55.734783Z",
     "shell.execute_reply": "2021-12-21T17:46:55.733834Z",
     "shell.execute_reply.started": "2021-12-21T17:46:08.769535Z"
    },
    "papermill": {
     "duration": 2.800435,
     "end_time": "2021-12-21T17:46:55.734968",
     "exception": false,
     "start_time": "2021-12-21T17:46:52.934533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345ef8df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T17:46:55.777183Z",
     "iopub.status.busy": "2021-12-21T17:46:55.754689Z",
     "iopub.status.idle": "2021-12-21T17:46:55.779753Z",
     "shell.execute_reply": "2021-12-21T17:46:55.779094Z",
     "shell.execute_reply.started": "2021-12-21T17:46:11.170005Z"
    },
    "papermill": {
     "duration": 0.03565,
     "end_time": "2021-12-21T17:46:55.779911",
     "exception": false,
     "start_time": "2021-12-21T17:46:55.744261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PawpularityDataset(Dataset):\n",
    "    def __init__(self, main_dir, imgs, labels, meta, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        self.all_imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.meta = meta\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.all_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image, self.meta[idx], self.labels[idx]\n",
    "\n",
    "def load_imgs(folder, batch_size=64, val_size=0):\n",
    "    # fetch filenames\n",
    "    main_dir = '../input/petfinder-pawpularity-score/{}'.format(folder)\n",
    "    img_paths = os.listdir(main_dir)\n",
    "    meta_data = pd.read_csv(\"../input/petfinder-pawpularity-score/{}.csv\".format(folder))\n",
    "    if folder == 'test':\n",
    "        features = meta_data.columns[1:]\n",
    "    else:\n",
    "        features = meta_data.columns[1:-1]\n",
    "    \n",
    "    # fetch labels\n",
    "    if folder == 'train':\n",
    "        labels_dict = dict()\n",
    "        for i in range(len(meta_data)):\n",
    "            labels_dict[meta_data['Id'][i]] = meta_data['Pawpularity'][i]\n",
    "\n",
    "        labels = list()\n",
    "        for img in img_paths:\n",
    "            labels.append(labels_dict[img.split('.')[0]])\n",
    "    else:\n",
    "        labels = [-1 for i in range(len(img_paths))]\n",
    "    \n",
    "    # fetch meta data\n",
    "    meta_dict = dict()\n",
    "    meta = meta_data[features].to_numpy()\n",
    "    for i in range(len(meta_data)):\n",
    "        meta_dict[meta_data['Id'][i]] = meta[i]\n",
    "    meta = list()\n",
    "    for img in img_paths:\n",
    "        meta.append(meta_dict[img.split('.')[0]])\n",
    "    \n",
    "    img_paths = np.array(img_paths)\n",
    "    labels = np.array(labels)\n",
    "    meta = np.array(meta)\n",
    "    \n",
    "    # split if test_size > 0\n",
    "    if val_size > 0:\n",
    "        inds = [i for i in range(len(img_paths))]\n",
    "        np.random.shuffle(inds)\n",
    "        split_ind = int(len(inds) * val_size)\n",
    "        train_inds = inds[split_ind:]\n",
    "        val_inds = inds[:split_ind]\n",
    "\n",
    "    # declare preprocess (add augmentation here)\n",
    "    train_preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    val_preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # construct dataset and dataloader    \n",
    "    if folder == 'test':\n",
    "        dataset = PawpularityDataset(main_dir=main_dir, imgs=img_paths, labels=labels, meta=meta, transform=val_preprocess)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        return dataloader\n",
    "    else:\n",
    "        if val_size == 0:\n",
    "            train_dataset = PawpularityDataset(main_dir=main_dir, imgs=img_paths, labels=labels, meta=meta, transform=train_preprocess)\n",
    "            train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False) # change shuflle here if do not wanna shuffle\n",
    "            return train_dataloader\n",
    "        \n",
    "        train_dataset = PawpularityDataset(main_dir=main_dir, imgs=img_paths[train_inds], labels=labels[train_inds], meta=meta[train_inds], transform=train_preprocess)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # change shuflle here if do not wanna shuffle\n",
    "        \n",
    "        val_dataset = PawpularityDataset(main_dir=main_dir, imgs=img_paths[val_inds], labels=labels[val_inds], meta=meta[val_inds], transform=val_preprocess)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d296e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T17:46:55.808304Z",
     "iopub.status.busy": "2021-12-21T17:46:55.806968Z",
     "iopub.status.idle": "2021-12-21T17:46:55.809019Z",
     "shell.execute_reply": "2021-12-21T17:46:55.809501Z",
     "shell.execute_reply.started": "2021-12-21T17:46:11.195219Z"
    },
    "papermill": {
     "duration": 0.023195,
     "end_time": "2021-12-21T17:46:55.809672",
     "exception": false,
     "start_time": "2021-12-21T17:46:55.786477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.fc_liner = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 2, out_size),\n",
    "            nn.Softplus(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc_liner(x).squeeze()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "class FineTuneModel(nn.Module):\n",
    "    def __init__(self, latent_size, hidden_size, out_size, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        # load pretrained model\n",
    "        with open('../input/resnet18/resnet18.pkl', 'rb') as f:\n",
    "            pretrain_model = pickle.load(f)\n",
    "            self.pretrain_feat = nn.Sequential(*(list(pretrain_model.children())[:-1]))\n",
    "        \n",
    "        # make the model fine-tuned\n",
    "        for param in self.pretrain_feat.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # construct the final output layer(s)\n",
    "        self.regressor = Regressor(latent_size, hidden_size, out_size)\n",
    "    \n",
    "    def forward(self, x, meta):\n",
    "        feat_out = self.pretrain_feat(x).squeeze()\n",
    "        # do something with meta data\n",
    "        N, D = feat_out.shape\n",
    "        N, M = meta.shape\n",
    "        out = torch.zeros((N, D+M)).to(self.device)\n",
    "        out[:, :D] = feat_out\n",
    "        out[:, D: ] = meta\n",
    "        return self.regressor(out).squeeze()\n",
    "    \n",
    "    def predict(self, x, meta):\n",
    "        return self.forward(x, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85932c03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T17:46:55.827116Z",
     "iopub.status.busy": "2021-12-21T17:46:55.826123Z",
     "iopub.status.idle": "2021-12-21T17:46:59.517237Z",
     "shell.execute_reply": "2021-12-21T17:46:59.517721Z",
     "shell.execute_reply.started": "2021-12-21T17:46:11.211603Z"
    },
    "papermill": {
     "duration": 3.701497,
     "end_time": "2021-12-21T17:46:59.517936",
     "exception": false,
     "start_time": "2021-12-21T17:46:55.816439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "Load well-trained model...\n",
      "Num params: 21719617\n"
     ]
    }
   ],
   "source": [
    "# use gpu if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('device:', device)\n",
    "\n",
    "# laod trained model\n",
    "print('Load well-trained model...')\n",
    "latent_out = 524\n",
    "hidden_size = 4096\n",
    "model = FineTuneModel(latent_out, hidden_size, 1, device).to(device)\n",
    "model.load_state_dict(torch.load('../input/pawpularity-resnet18-2layer-mlp/resnet18_2layer_mlp.model'))\n",
    "model.eval()\n",
    "\n",
    "print('Num params:', sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04e0de9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T17:46:59.536721Z",
     "iopub.status.busy": "2021-12-21T17:46:59.536070Z",
     "iopub.status.idle": "2021-12-21T17:47:00.262518Z",
     "shell.execute_reply": "2021-12-21T17:47:00.261785Z",
     "shell.execute_reply.started": "2021-12-21T17:46:13.641191Z"
    },
    "papermill": {
     "duration": 0.736698,
     "end_time": "2021-12-21T17:47:00.262665",
     "exception": false,
     "start_time": "2021-12-21T17:46:59.525967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct dataloaders...\n",
      "Making predictions...\n",
      "Write to file...\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "print('Construct dataloaders...')\n",
    "test_dataloader = load_imgs('test', batch_size=128, val_size=0)\n",
    "\n",
    "# iterate over test data\n",
    "print('Making predictions...')\n",
    "test_pred = list()\n",
    "for test_images, test_meta, test_labels in test_dataloader:\n",
    "    test_images = test_images.to(device).float()\n",
    "    test_meta = test_meta.to(device).float()\n",
    "\n",
    "    # forward\n",
    "    test_pred += model.predict(test_images, test_meta).cpu().detach().numpy().tolist()\n",
    "\n",
    "# write to file\n",
    "print('Write to file...')\n",
    "ids = pd.read_csv(\"../input/petfinder-pawpularity-score/{}.csv\".format('test'))['Id']\n",
    "output = pd.DataFrame({\"Id\": ids, \"Pawpularity\": test_pred})\n",
    "output.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a748c74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T17:47:00.282615Z",
     "iopub.status.busy": "2021-12-21T17:47:00.281937Z",
     "iopub.status.idle": "2021-12-21T17:47:00.301372Z",
     "shell.execute_reply": "2021-12-21T17:47:00.300734Z",
     "shell.execute_reply.started": "2021-12-21T17:46:14.435168Z"
    },
    "papermill": {
     "duration": 0.030643,
     "end_time": "2021-12-21T17:47:00.301522",
     "exception": false,
     "start_time": "2021-12-21T17:47:00.270879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>14.408893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>17.695114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>16.995123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>14.986017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>16.237005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b03f7041962238a7c9d6537e22f9b017</td>\n",
       "      <td>15.443115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c978013571258ed6d4637f6e8cc9d6a3</td>\n",
       "      <td>15.800261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e0de453c1bffc20c22b072b34b54e50f</td>\n",
       "      <td>14.397794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Pawpularity\n",
       "0  4128bae22183829d2b5fea10effdb0c3    14.408893\n",
       "1  43a2262d7738e3d420d453815151079e    17.695114\n",
       "2  4e429cead1848a298432a0acad014c9d    16.995123\n",
       "3  80bc3ccafcc51b66303c2c263aa38486    14.986017\n",
       "4  8f49844c382931444e68dffbe20228f4    16.237005\n",
       "5  b03f7041962238a7c9d6537e22f9b017    15.443115\n",
       "6  c978013571258ed6d4637f6e8cc9d6a3    15.800261\n",
       "7  e0de453c1bffc20c22b072b34b54e50f    14.397794"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check output\n",
    "output_df = pd.read_csv('submission.csv')\n",
    "output_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.390807,
   "end_time": "2021-12-21T17:47:01.221760",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-21T17:46:41.830953",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
