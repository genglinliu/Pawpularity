{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af8fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages and utils\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import PIL.Image as Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from models.vgg16 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c352e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config   \n",
    "\n",
    "data_dir = \"../data/petfinder-pawpularity-score/\"\n",
    "\n",
    "num_classes = 1 # for regression\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# model_name = vgg16_bn(pretrained=True) # baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50bc11f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "display(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959f4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Dataset - might need modification later for covariates idk yet\n",
    "\n",
    "class PetDataset(Dataset):\n",
    "    def __init__(self, image_filepaths, targets, transform=None):\n",
    "        self.image_filepaths = image_filepaths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_filepaths[idx]\n",
    "        \n",
    "        with open(image_filepath, 'rb') as f:\n",
    "            image = Image.open(f)\n",
    "            image_rgb = image.convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        target = torch.tensor(self.targets[idx])\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d7712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cvs data into dataframes\n",
    "\n",
    "def get_dataframe(data_dir, is_train=True):\n",
    "    \n",
    "    if is_train:\n",
    "        image_dir = os.path.join(data_dir, 'train')\n",
    "        file_path = os.path.join(data_dir, 'train.csv')\n",
    "    else:\n",
    "        image_dir = os.path.join(data_dir, 'test')\n",
    "        file_path = os.path.join(data_dir, 'test.csv')\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # set image filepath\n",
    "    df['img_file_path'] = df['Id'].apply(lambda x: os.path.join(image_dir, f'{x}.jpg'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = get_dataframe(data_dir, is_train=True)\n",
    "test_df = get_dataframe(data_dir, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0814b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get DataLoader\n",
    "\n",
    "def load_data(batch_size, is_train=True, use_subset=False):\n",
    "    \"\"\"\n",
    "    return the train dataloader\n",
    "    \"\"\"\n",
    "    \n",
    "    if is_train:\n",
    "        df = get_dataframe(data_dir, is_train=True)\n",
    "        images = np.array(df['img_file_path'])\n",
    "        targets = np.array(df['Pawpularity'])\n",
    "    else:\n",
    "        df = get_dataframe(data_dir, is_train=False)\n",
    "        images = np.array(df['img_file_path'])\n",
    "        targets = np.zeros_like(images)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)\n",
    "    ])\n",
    "    \n",
    "    dataset = PetDataset(image_filepaths=images, targets=targets, transform=transform)\n",
    "    \n",
    "    subse_ind = list(range(500))\n",
    "    \n",
    "    data_subset = Subset(dataset, subse_ind)\n",
    "\n",
    "    # data loader\n",
    "    data_loader = DataLoader(dataset=data_subset if use_subset else dataset, \n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "    \n",
    "    return data_loader\n",
    "\n",
    "train_loader = load_data(batch_size, is_train=True, use_subset=True)\n",
    "test_loader = load_data(batch_size, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7acc3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model, loss function and optimizer\n",
    "\n",
    "def initialize_model(model, learning_rate, num_classes):\n",
    "    \"\"\"\n",
    "    initialize the model\n",
    "    define loss function and optimizer and move data to gpu if available\n",
    "    \n",
    "    return:\n",
    "        model, loss function(criterion), optimizer\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(model, VGG):\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return model, criterion, optimizer\n",
    "\n",
    "model_name = vgg16_bn(pretrained=True)\n",
    "\n",
    "model, criterion, optimizer = initialize_model(model_name, learning_rate, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1350f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting loss curve\n",
    "\n",
    "def make_plots(step_hist, loss_hist):\n",
    "    plt.plot(step_hist, loss_hist)\n",
    "    plt.xlabel('train_iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(experiment_name)\n",
    "    plt.show()\n",
    "    plt.savefig(experiment_name)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b07b321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "experiment_name = \"simple_run\"\n",
    "\n",
    "def calc_rmse(y_pred, y_true):\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    Move data to GPU memory\n",
    "    Also plot the loss function and save it in `Figures/`\n",
    "    Trained model is saved as `cnn.ckpt`\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # for each training sample\n",
    "    loss_hist = []\n",
    "    step_hist = []\n",
    "    for i, (images, label) in (enumerate(train_loader)):\n",
    "\n",
    "        train_pred = list()\n",
    "        train_true = list()\n",
    "\n",
    "        # move to gpu if available\n",
    "        images = images.to(device).float()\n",
    "        label = label.to(device).float()\n",
    "\n",
    "        # forward pass\n",
    "        out = model(images)\n",
    "        loss = torch.sqrt(criterion(out, label))\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 50 == 0:\n",
    "            train_true += label.cpu().detach().numpy().tolist()\n",
    "            train_pred += out.cpu().detach().numpy().tolist()\n",
    "\n",
    "            train_rmse = calc_rmse(np.array(train_pred), np.array(train_true))\n",
    "            \n",
    "            step_hist.append(i+1)\n",
    "            loss_hist.append(train_rmse)\n",
    "            print('Iteration: {}, Train rmse: {}'.format(i+1, train_rmse))\n",
    "            \n",
    "    # plot\n",
    "    make_plots(step_hist, loss_hist)\n",
    "\n",
    "    torch.save(model.state_dict(), experiment_name+'.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f620052c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\genglinliu\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:446: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 4.00 GiB total capacity; 2.47 GiB already allocated; 258.29 MiB free; 2.54 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f2347c8726e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-0eec4d3b070f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# backprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 4.00 GiB total capacity; 2.47 GiB already allocated; 258.29 MiB free; 2.54 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "train(train_loader, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b95d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "\n",
    "def evaluation(test_loader, model):\n",
    "    model.eval() \n",
    "    print('Making predictions...')\n",
    "    test_pred = []    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for test_images, test_labels in test_loader:\n",
    "            test_images = test_images.to(device).float()\n",
    "            # forward\n",
    "            out = model(test_images)\n",
    "            test_pred += out.cpu().numpy().tolist()\n",
    "\n",
    "        # write to file\n",
    "        output = pd.DataFrame({\"Id\": test_df['Id'], \"Pawpularity\": test_pred})\n",
    "        output.to_csv('submission.csv', index = False)\n",
    "\n",
    "        # check output\n",
    "        output_df = pd.read_csv('submission.csv')\n",
    "\n",
    "        return output_df\n",
    "\n",
    "evaluation(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cddb7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
