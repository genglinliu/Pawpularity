{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af8fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages and utils\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import PIL.Image as Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from models.vgg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b8cf39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = vgg11_bn(pretrained=True)\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config   \n",
    "\n",
    "data_dir = \"../data/petfinder-pawpularity-score/\"\n",
    "\n",
    "num_classes = 1 # for regression\n",
    "batch_size = 8\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# model_name = vgg16_bn(pretrained=True) # baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "display(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Dataset - might need modification later for covariates idk yet\n",
    "\n",
    "class PawpularityDataset(Dataset):\n",
    "    def __init__(self, image_filepaths, covariates, targets, transform):\n",
    "        self.image_filepaths = image_filepaths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.covaraites_all = covariates\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_filepaths[idx]\n",
    "        covaraites_per_image = torch.tensor(self.covaraites_all[idx])\n",
    "        target = torch.tensor(self.targets[idx])\n",
    "        \n",
    "        with open(image_filepath, 'rb') as f:\n",
    "            image = Image.open(f)\n",
    "            image = image.convert('RGB')\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, covaraites_per_image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cvs data into dataframes\n",
    "\n",
    "def get_dataframe(data_dir, is_train=True):\n",
    "    \n",
    "    if is_train:\n",
    "        image_dir = os.path.join(data_dir, 'train')\n",
    "        file_path = os.path.join(data_dir, 'train.csv')\n",
    "    else:\n",
    "        image_dir = os.path.join(data_dir, 'test')\n",
    "        file_path = os.path.join(data_dir, 'test.csv')\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # set image filepath\n",
    "    df['img_file_path'] = df['Id'].apply(lambda x: os.path.join(image_dir, f'{x}.jpg'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = get_dataframe(data_dir, is_train=True)\n",
    "test_df = get_dataframe(data_dir, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c377fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0814b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get DataLoader\n",
    "\n",
    "def load_data(batch_size, is_train=True, use_subset=False):\n",
    "    \"\"\"\n",
    "    return the train dataloader\n",
    "    \"\"\"\n",
    "    \n",
    "    if is_train:\n",
    "        df = get_dataframe(data_dir, is_train=True)\n",
    "        images = np.array(df['img_file_path'])\n",
    "        covariates = df.iloc[:, 2:13].to_numpy()\n",
    "        targets = np.array(df['Pawpularity'])\n",
    "    else:\n",
    "        df = get_dataframe(data_dir, is_train=False)\n",
    "        images = np.array(df['img_file_path'])\n",
    "        covariates = df.iloc[:, 2:13].to_numpy()\n",
    "        targets = np.zeros_like(images)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)\n",
    "    ])\n",
    "    \n",
    "    dataset = PawpularityDataset(image_filepaths=images, covariates=covariates, targets=targets, transform=transform)\n",
    "    \n",
    "    subse_ind = list(range(500))\n",
    "    \n",
    "    data_subset = Subset(dataset, subse_ind)\n",
    "\n",
    "    # data loader\n",
    "    data_loader = DataLoader(dataset=data_subset if use_subset else dataset, \n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "    \n",
    "    return data_loader\n",
    "\n",
    "train_loader = load_data(batch_size, is_train=True, use_subset=True)\n",
    "test_loader = load_data(batch_size, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model, loss function and optimizer\n",
    "\n",
    "def initialize_model(model, learning_rate, num_classes):\n",
    "    \"\"\"\n",
    "    initialize the model\n",
    "    define loss function and optimizer and move data to gpu if available\n",
    "    \n",
    "    return:\n",
    "        model, loss function(criterion), optimizer\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(model, VGG):\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return model, criterion, optimizer\n",
    "\n",
    "model_name = vgg16_bn(pretrained=True)\n",
    "\n",
    "model, criterion, optimizer = initialize_model(model_name, learning_rate, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting loss curve\n",
    "\n",
    "def make_plots(step_hist, loss_hist):\n",
    "    plt.plot(step_hist, loss_hist)\n",
    "    plt.xlabel('train_iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(experiment_name)\n",
    "    plt.show()\n",
    "    plt.savefig(experiment_name)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check network input shapes\n",
    "for i, (images, covariates, label) in enumerate(train_loader):\n",
    "\n",
    "        train_pred = list()\n",
    "        train_true = list()\n",
    "\n",
    "        # move to gpu if available\n",
    "        images = images.to(device).float()\n",
    "        covariates = covariates.to(device)\n",
    "        label = label.to(device).float()\n",
    "        \n",
    "        display(images.shape, covariates.shape, label.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "experiment_name = \"simple_run\"\n",
    "\n",
    "def calc_rmse(y_pred, y_true):\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    Move data to GPU memory\n",
    "    Also plot the loss function and save it in `Figures/`\n",
    "    Trained model is saved as `cnn.ckpt`\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # for each training sample\n",
    "    loss_hist = []\n",
    "    step_hist = []\n",
    "    for i, (images, covariates, label) in enumerate(train_loader):\n",
    "\n",
    "        train_pred = list()\n",
    "        train_true = list()\n",
    "\n",
    "        # move to gpu if available\n",
    "        images = images.to(device).float()\n",
    "        covariates = covariates.to(device)\n",
    "        label = label.to(device).float()\n",
    "        \n",
    "        display(images.shape, covariates, label)\n",
    "\n",
    "#         # forward pass\n",
    "#         out = model(images)\n",
    "#         loss = torch.sqrt(criterion(out, label))\n",
    "\n",
    "#         # backprop\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if (i+1) % 50 == 0:\n",
    "#             train_true += label.cpu().detach().numpy().tolist()\n",
    "#             train_pred += out.cpu().detach().numpy().tolist()\n",
    "\n",
    "#             train_rmse = calc_rmse(np.array(train_pred), np.array(train_true))\n",
    "            \n",
    "#             step_hist.append(i+1)\n",
    "#             loss_hist.append(train_rmse)\n",
    "#             print('Iteration: {}, Train rmse: {}'.format(i+1, train_rmse))\n",
    "            \n",
    "#     # plot\n",
    "#     make_plots(step_hist, loss_hist)\n",
    "\n",
    "#     torch.save(model.state_dict(), experiment_name+'.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_loader, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b95d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "\n",
    "def evaluation(test_loader, model):\n",
    "    model.eval() \n",
    "    print('Making predictions...')\n",
    "    test_pred = []    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for test_images, test_labels in test_loader:\n",
    "            test_images = test_images.to(device).float()\n",
    "            # forward\n",
    "            out = model(test_images)\n",
    "            test_pred += out.cpu().numpy().tolist()\n",
    "\n",
    "        # write to file\n",
    "        output = pd.DataFrame({\"Id\": test_df['Id'], \"Pawpularity\": test_pred})\n",
    "        output.to_csv('submission.csv', index = False)\n",
    "\n",
    "        # check output\n",
    "        output_df = pd.read_csv('submission.csv')\n",
    "\n",
    "        return output_df\n",
    "\n",
    "evaluation(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cddb7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
